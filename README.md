# Transformer-Based Paraphrase Generation System using LLM T5

# Paraphrase Generation Using T5 Fine-Tuning

This repository contains code and resources for generating paraphrases using the T5 (Text-to-Text Transfer Transformer) model. The project focuses on fine-tuning T5 for paraphrase generation, specifically utilizing the PAWS (Paraphrase Adversaries from Word Scrambling) dataset.

## Overview

The goal of this project is to leverage the T5 model's capabilities for text generation to create accurate and diverse paraphrases of input sentences. By fine-tuning T5 on the PAWS dataset, we aim to achieve high-quality paraphrase generation.

## Key Features

*   **T5 Fine-tuning:** Employs the T5 model, a powerful text-to-text transformer, for paraphrase generation.
*   **PAWS Dataset:** Utilizes the PAWS dataset, a benchmark for paraphrase detection and generation.
*   **End-to-End Paraphrase Generation:** Provides a complete pipeline for training and evaluating a paraphrase generation model.

## Requirements

*   Python 3.7+
*   PyTorch
*   Transformers library
